## Effect of PRG Quality on Hash Tables ##

he common problem of having the ability to maintain a set of elements from a large universal space that may change over time has bred a solid offering of hashing algorithms.  However, some of the best of these algorithms need random number generators.  Since purely random functions cannot be implemented, the best we have is pseudo-random number generators.  Of course, not all algorithms are created equal, and so some will produce numbers that are "more random" than others will.

Randomness can be defined as the lack of a discernible pattern.  For a sequence of numbers, or values in general, to be random, then what number (or value) is at a given position in the sequence is not determined or predictable based on its position, the previous numbers or values in the sequence, or any other discernible basis.  Statistically speaking, the value each position in a sequence is independent of everything, for some vague definition of everything.  So asking "how random" a sequence of values is equivalent to asking "how difficult" it is to predict a value in the sequence given the preceding values.  So to test "how random" a sequence of values is, we can try to find patterns or biases in a given sequence.

There are many standard empirical tests that determine how random the products of pseudo-random number generators are.  In general, they attempt pattern matching on or measuring for some bias in a given sequence.  However, these empirical tests do not test the randomness of the pseudo-random number generators themselves, but their output.  This distinction, while subtle, is important.  For example, a theoretic pure random number generator can conceivable generate a sequence that contains only one's (i.e. 11111...).  While this sequence was generated randomly, the sequence itself exhibits a pattern.  Transient patterns (and biases) can also obviously appear in sequences generated by pseudo-random number generators.  In fact, by definition pseudo-random number generators have persistent biases and patterns.  For example, as will be discussed below, in the sequences produced by the PRand generator the numbers alternates between even and odd, which means the least significant bit has a constant pattern. These qualities can be measured by the empirical tests, so how frequent they appear can also be measured.

However, applications requiring randomness may be hindered, not be affected, or even benefit by such biases and patterns.  For a simplistic example, the alternating even and odd pattern of PRand's sequences means that no two consecutive numbers in the sequence will be equal.  It is theoretically possible that some application, such as a hashing scheme, would benefit from this small guarantee of non-repetition.

In this project we took a selection of pseudo-random number generators (PRNG), hashing functions and hashing schemes and investigate the variations of performance of their combinations in a hash table benchmark. Using known statistical methods of measuring PRNGs quality, we  derive a ranking of the PRNGs based on how often empirical tests find obvious patters or biases. Because hash functions consume random numbers and should produce uniformly distributed outputs, we used the same measurement methods on the output of our hashing functions based on their use of various PRNGs. Finally we implemented different hashing schemes to test the performance of a hash table inserts, lookups and deletes based on their use of the different hash functions crossed with the different PRNGs. With this approach, we hope to show how randomness used in hash functions effects the performance of hash tables and what combinations show the greatest performance empirically.


## Project Report ##
Can be found here:

http://hash-metrics.googlecode.com/svn/trunk/HashMetricsPaper.pdf